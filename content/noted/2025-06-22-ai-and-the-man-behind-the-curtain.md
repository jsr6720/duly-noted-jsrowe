---
title: "AI and the man behind the curtain"
author: "Commonplace Book Tools Bot"
date: "2025-06-22T23:26:25.329671+00:00"
generated: "2025-06-27T23:51:31-05:00"
tags:
  - ai
isBasedOn:
  type: "NewsArticle"
  headline: "What Happens When People Don’t Understand How AI Works"
  url: "https://www.theatlantic.com/culture/archive/2025/06/artificial-intelligence-illiteracy/683021/"
  author: "Tyler Austin Harper"
  datePublished: "JUNE 6, 2025"
  publisher: "www.theatlantic.com"
guid: "8974cabc-611c-450a-b41d-27f17ca36036"
---

> These statements betray a conceptual error: Large language models do not, cannot, and will not “understand” anything at all. They are not emotionally intelligent or smart in any meaningful or recognizably human sense of the word. LLMs are impressive probability gadgets that have been fed nearly the entire internet, and produce writing not by thinking but by making statistically informed guesses about which lexical item is likely to follow another.

While it is an oversimplification to assert that LLM are statistically chained words, it does quickly get at the heart of the matter. I think the most dangerous thing is, one you have no idea where your prompts and deep coversations go. And two, the machine is trained to reinforce your sentiment. Even if you tell it to disagree or agree. Just as there was internet literacy, we will need AI literacy for citizens.

---

<sub>Quote Citation: <cite>Tyler Austin Harper, "What Happens When People Don’t Understand How AI Works", JUNE 6, 2025, <a href="https://www.theatlantic.com/culture/archive/2025/06/artificial-intelligence-illiteracy/683021/">https://www.theatlantic.com/culture/archive/2025/06/artificial-intelligence-illiteracy/683021/</a></cite></sub>