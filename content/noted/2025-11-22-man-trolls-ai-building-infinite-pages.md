---
title: "man trolls ai - building infinite pages"
author: "Commonplace Book Tools Bot"
date: "2025-11-22T02:33:07.237656+00:00"
generated: "2025-11-23T19:16:02-05:00"
tags:
  - internet
  - cybercrime
isBasedOn:
  type: "BlogPosting"
  headline: "Goofing on Meta's AI Crawler - Information Camouflage"
  url: "https://bruceediger.com/posts/goofing-on-meta/"
  author: "bruceediger.com"
  datePublished: "2025-11-13"
  publisher: "bruceediger.com"
guid: "6d802492-b8b9-483e-890a-9305f9d5de4c"
---

> Meta is a terrible company. They aren’t being at all mannerly scraping everything. At the very least, the effects of copyright law on their use of human-written material is arguable. I feel that we should all give fake content to Meta’s AI scraper, or something similar. I believe that every time someone implements a scraper junkyard, it should be individual, highly customized, and idiosyncratic, in order to give the people at Meta, Google, OpenAI and others problems. I quit goofing on Meta because I was worried about costs of ridiculously high traffic to my $6-a-month VPS. I should probably have written my infinite website program with some kind of rate limiting, a fixed number of requests per day perhaps, and then give out 503s the rest of the day. bork.php already waits a randomly-chosen delay with a mean of about 14 seconds on each request.

I think the sentiment here is 10000% correct. And I'm glad someone made a molasses of a black hole.

---

<sub>Quote Citation: <cite>bruceediger.com, "Goofing on Meta's AI Crawler - Information Camouflage", 2025-11-13, <a href="https://bruceediger.com/posts/goofing-on-meta/">https://bruceediger.com/posts/goofing-on-meta/</a></cite></sub>