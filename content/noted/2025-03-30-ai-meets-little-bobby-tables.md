---
title: "AI meets little bobby tables"
author: "Commonplace Book Tools Bot"
date: "2025-03-30T02:50:17.642589"
generated: "2025-03-29T23:27:14-05:00"
tags:
  - ai
  - xkcd
isBasedOn:
  type: "BlogPosting"
  headline: "How AI coding assistants could be compromised via rules file"
  url: "https://www.scworld.com/news/how-ai-coding-assistants-could-be-compromised-via-rules-file"
  author: "Laura French"
  datePublished: "March 18, 2025"
  publisher: "www.scworld.com"
guid: "d151f077-c1c0-4306-ac50-c24162a37a9c"
---

>The attack technique developed by Pillar Researchers, which they call 'Rules File Backdoor,' weaponizes rules files by injecting them with instructions that are invisible to a human user but readable by the AI agent.

xkcd taught me anything, its to sanitize my inputs

---

<sub>Quote Citation: <cite>Laura French, "How AI coding assistants could be compromised via rules file", March 18, 2025, <a href="https://www.scworld.com/news/how-ai-coding-assistants-could-be-compromised-via-rules-file">https://www.scworld.com/news/how-ai-coding-assistants-could-be-compromised-via-rules-file</a></cite></sub>