---
title: "AI, LLM and attack vectors"
author: "Commonplace Book Tools Bot"
date: "2025-06-22T23:21:02.262204+00:00"
generated: "2025-06-27T23:51:36-05:00"
tags:
  - ai
  - security
isBasedOn:
  type: "BlogPosting"
  headline: "The lethal trifecta for AI agents: private data, untrusted content, and external communication"
  url: "https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/"
  author: "Emily Peck"
  datePublished: "16th June 2025 at 1:20 pm"
  publisher: "simonwillison.net"
guid: "f6c202e9-9b91-47e5-80d5-eb7c4e2502dd"
---

> The bad news is that once you start mixing and matching tools yourself thereâ€™s nothing those vendors can do to protect you! Any time you combine those three lethal ingredients together you are ripe for exploitation.

With the rise of LLMs is now ripe for exploitation. Target your LLM to your email? What happens when there is mallicious prompts in plain text? Will be interesting to see how this plays out.

---

<sub>Quote Citation: <cite>Emily Peck, "The lethal trifecta for AI agents: private data, untrusted content, and external communication", 16th June 2025 at 1:20 pm, <a href="https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/">https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/</a></cite></sub>